{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e135a699-b711-48ef-8f51-3f6e72bf5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "API_KEY = \"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\"\n",
    "#API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc186c95-0b83-4bbf-a9aa-7173c209284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq (api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc12559f-1179-403d-b679-2bec06af78bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\{'\n",
      "/var/folders/qt/q5s0yg0959d5b540drdr9xpc0000gn/T/ipykernel_32209/3301045405.py:17: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  Find the entities in the followning sentence : \"+sentence+\"\\nTHe output should\\\n"
     ]
    }
   ],
   "source": [
    "def some_shots_qwen (sentence):   \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-2.5-32b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"An entity is : \\\n",
    "                 -a person or a collective of persons (PER) \\\n",
    "                     e.g. The Beatles, Gandhi \\\n",
    "                 - an organisation (ORG)\\\n",
    "                     e.g. Musée du Louvres, NBA \\\n",
    "                 - a location (LOC) \\\n",
    "                     e.g. China, Les Alpes \\\n",
    "                 - or miscellaneous (MISC), \\\n",
    "                    which can be events, brands, function, etc. \\\n",
    "                    e.g. World Chess Championship, Officier\\\n",
    "                Find the entities in the followning sentence : \"+sentence+\"\\nTHe output should\\\n",
    "                be json in the format \\{'entities':[\\{'entity':text, 'type':type\\},...]\\}.\\\n",
    "                Determiners (le, la, ...) should not be included\\n\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.6,\n",
    "        max_completion_tokens=4096,\n",
    "        top_p=0.95,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    result_raw = \"\"\n",
    "    for chunk in completion:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content :\n",
    "            result_raw += content\n",
    "    #print(result_raw)\n",
    "    \n",
    "    #print(\"-\"*44)\n",
    "    json_raw = \"\"\n",
    "    json_flag = False\n",
    "    for line in result_raw.split(\"\\n\"):\n",
    "        \n",
    "        if line == \"```\" or line==\"```json\":\n",
    "            json_flag = not json_flag\n",
    "        elif json_flag: \n",
    "            json_raw+=line +\"\\n\"\n",
    "            \n",
    "    #print(json_raw)\n",
    "    try:\n",
    "        entities =  json.loads (json_raw)\n",
    "    except:\n",
    "        entities = {}\n",
    "    return entities\n",
    "\n",
    "    \n",
    "def add_entities_index (entities,sentence, offset):\n",
    "    sentence_lower = sentence.lower()\n",
    "    if 'entities' in entities:\n",
    "        for entity in entities['entities']:\n",
    "            \n",
    "            text = entity[\"entity\"]\n",
    "            if text.lower() in sentence_lower:\n",
    "                start = sentence_lower.index (text.lower())\n",
    "            else:\n",
    "                # There can be problems with some spaces : e.g. d' Actium in the original text\n",
    "                # and d'Actium in the LLM output \n",
    "                splitted_text =  text.lower().replace(\"'\",\" \").split(\" \")\n",
    "                # VERY RUDIMENTARY SOLUTION HERE\n",
    "                # TODO : CHANGE THIS\n",
    "                if splitted_text[0] in sentence_lower and splitted_text[-1] in sentence_lower:\n",
    "                    start = sentence_lower.index (splitted_text[0])\n",
    "                else:\n",
    "                    print(text, \"not in\", sentence)\n",
    "                    continue\n",
    "                \n",
    "            end = start + len (text)\n",
    "            entity[\"start\"] = start + offset\n",
    "            entity [\"end\"] = end + offset\n",
    "            \n",
    "                \n",
    "                        \n",
    "\n",
    "def entities_to_ann (entities):\n",
    "    ann = \"\"\n",
    "    for i, entity in enumerate(entities):\n",
    "        if 'start' in entity and 'end' in entity:\n",
    "            ann += f\"T{i+1}\\t{entity['type']} {entity['start']} {entity['end']}\\t{entity['entity']}\\n\"\n",
    "    return ann\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2811f697-5f88-4beb-b698-a7e040e6a9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FENEC/encyclopedia01-WikiNER.txt\n",
      "FENEC/multi03-FQB.txt\n",
      "FENEC/prose03-Giono.txt\n",
      "FENEC/information01-APIL.txt\n",
      "mètre not in BERULLE - à 18 h profitez des conditions de l’Espace Jean Musy pour faire un passage sur scène : musique, poésie, danse, sketchs, acrobatie, etc. Une soirée unique chaque année ! Scène ouverte à tous sur inscription uniquement 03 25 42 59 34 – entrée libre, tout public.\n",
      "\n",
      "FENEC/spoken01-Rhapsodie.txt\n",
      "FENEC/multi02-Sequoia.txt\n",
      "The Beatles not in Distribution :\n",
      "\n",
      "Musée du Louvre not in Distribution :\n",
      "\n",
      "Paris not in Distribution :\n",
      "\n",
      "France not in Distribution :\n",
      "\n",
      "FENEC/information02-Wikinews.txt\n",
      "Russie not in La semaine dernière, le Royaume-Uni a déjà expulsé 23 diplomates russes.\n",
      "\n",
      "groupe Bollé not in Le groupe Bolloré (Canal+) y voit une volonté de discrimination à l'encontre des téléspectateurs selon leur mode de réception.\n",
      "\n",
      "Chine not in Espace : la station spatiale chinoise Tiangong-1 retombera sur Terre début avril  Page actualisée : 4 mars 2018 — « Espace : la station spatiale chinoise Tiangong-1 est tombée dans le Pacifique »  14 mars 2018 .\n",
      "\n",
      "World Chess Championship not in Il reste cependant un dernier problème avant de pouvoir reprendre les véritables opérations de recherches : suite à la panne de la foreuse, le mécanisme qui tamise les débris et distribue la poudre de roche aux instruments du robot n'est plus utilisable.\n",
      "\n",
      "FENEC/multi01-UDFrenchGSD.txt\n",
      "FENEC/spoken02-Rhapsodie.txt\n",
      "FENEC/spoken03-Rhapsodie.txt\n",
      "FENEC/information03-LEstRepublicain.txt\n",
      "FENEC/prose02-Zola.txt\n",
      "FENEC/prose01-Voltaire.txt\n",
      "FENEC/poetry02-Rimbaud.txt\n",
      "FENEC/poetry01-Baudelaire.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in glob.glob(\"FENEC/*.txt\"):\n",
    "    print(file)\n",
    "\n",
    "    all_entities = []\n",
    "    with open(file,\"r\") as f:\n",
    "        offset = 0\n",
    "        for line in f: \n",
    "            chunks = [line]\n",
    "            if len(line)>=1000:\n",
    "                # BRUTAL\n",
    "                # TO CHANGE\n",
    "                chunks = [line[1000*i:1000*(i+1)] for i in range(len(line)//1000)]\n",
    "            for chunk in chunks:    \n",
    "                entities = some_shots_qwen (chunk)\n",
    "                add_entities_index (entities, chunk, offset)\n",
    "                if 'entities' in entities:\n",
    "                    all_entities += (entities['entities'])\n",
    "                offset += len(chunk)\n",
    "    ann_file = \"systems-outputs/original-tagsets/qwen/\"+os.path.basename(file).split(\".\")[0]+\".ann\"\n",
    "    with open(ann_file, \"w\") as f:\n",
    "        f.write (entities_to_ann (all_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e084a8-fea5-409f-9099-b64f67acf47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\{'\n",
      "/var/folders/qt/q5s0yg0959d5b540drdr9xpc0000gn/T/ipykernel_32209/143297168.py:7: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  \"content\": \"An entity is : \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entities': [{'entity': 'Lesbos', 'type': 'LOC'},\n",
       "  {'entity': 'Phrynés', 'type': 'PER'},\n",
       "  {'entity': 'Paphos', 'type': 'LOC'},\n",
       "  {'entity': 'Vénus', 'type': 'PER'},\n",
       "  {'entity': 'Sapho', 'type': 'PER'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def more_shots_qwen (sentence):   \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-2.5-32b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"An entity is : \\\n",
    "                 -a person or a collective of persons (PER) \\\n",
    "                     e.g. The Beatles, Gandhi \\\n",
    "                 - an organisation (ORG)\\\n",
    "                     e.g. Musée du Louvres, NBA \\\n",
    "                 - a location (LOC) \\\n",
    "                     e.g. China, Les Alpes \\\n",
    "                 - or miscellaneous (MISC), \\\n",
    "                    which can be events, function, etc. \\\n",
    "                    e.g. World Chess Championship, Officier\\\n",
    "                \\nPerform Named entity recognition on the given sentences. The output should\\\n",
    "                be json in the format \\{'entities':[\\{'entity':text, 'type':type\\},...]\\}.\\\n",
    "                Determiners (le, la, ...) should not be included\\n\"\n",
    "            },\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\":\"Le paysan toulousain René se baigne au bassin du Havre, la princesse Sisi reçoit le baiser de Poséidon vers Paris, se promenant au bord de la Seine.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"```json\n",
    "                {\n",
    "                  \"entities\": [\n",
    "                    {\"entity\": \"paysan\", \"type\": \"MISC\"},\n",
    "                    {\"entity\": \"René\", \"type\": \"PER\"},\n",
    "                    {\"entity\": \"bassin du Havre\", \"type\": \"LOC\"},\n",
    "                    {\"entity\": \"princesse\", \"type\": \"MISC\"}\n",
    "                    {\"entity\": \"Sisi\", \"type\": \"PER\"},\n",
    "                    {\"entity\": \"Poséidon\", \"type\": \"PER\"},\n",
    "                    {\"entity\": \"Paris\", \"type\": \"LOC\"},\n",
    "                    {\"entity\": \"Seine\", \"type\": \"LOC\"}\n",
    "                  ]\n",
    "                }\n",
    "                ```\"\"\"\n",
    "                \n",
    "            },\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\":\"Non seulement Haiyan est responsable d'une hausse de l'humidité mais aussi une canicule arrivera bientôt.\"\n",
    "            },\n",
    "\n",
    "           {\n",
    "                \"role\":\"assistant\",\n",
    "                \"content\":\"\"\"```json\n",
    "                {\n",
    "                  \"entities\": [\n",
    "                    {\"entity\": \"Haiyan\", \"type\": \"MISC\"}\n",
    "                  ]\n",
    "                }\n",
    "                ```\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": sentence\n",
    "            },\n",
    "            \n",
    "            \n",
    "            \n",
    "        ],\n",
    "        temperature=0.6,\n",
    "        max_completion_tokens=4096,\n",
    "        top_p=0.95,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    result_raw = \"\"\n",
    "    for chunk in completion:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content :\n",
    "            result_raw += content\n",
    "    json_raw = \"\"\n",
    "    json_flag = False\n",
    "    for line in result_raw.split(\"\\n\"):\n",
    "        \n",
    "        if line == \"```\" or line==\"```json\":\n",
    "            json_flag = not json_flag\n",
    "            if not json_flag:\n",
    "                break\n",
    "        elif json_flag:\n",
    "            json_raw+=line +\"\\n\"\n",
    "            \n",
    "    try:\n",
    "        entities =  json.loads (json_raw)\n",
    "    except:\n",
    "        \n",
    "        entities = {}\n",
    "    return entities\n",
    "\n",
    "more_shots_qwen (\"Lesbos où les Phrynés l'une l'autre s'attirent, Où jamais un soupir ne resta sans écho, A l'égal de Paphos les étoiles t'admirent, Et Vénus à bon droit peut jalouser Sapho! --Lesbos où les Phrynés l'une l'autre s'attirent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6992d131-99f2-496e-bdef-22cbd8a320a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FENEC/prose03-Giono.txt\n",
      "FENEC/spoken01-Rhapsodie.txt\n",
      "FENEC/spoken02-Rhapsodie.txt\n",
      "outre-mer not in si poïésis a donné le mot poésie euh aisthesis a donné le terme esthétique à chacune et à chacun d' entre vous Françaises et Français de métropole d' outre - mer de l' étranger je souhaite très chaleureusement une bonne et une heureuse année deux mille il centre Agüero pour qui Rodriguez Rodriguez Rodriguez et les Argentins sous les ordres de Maradona euh jouaient un peu plus haut mh donc euh on voit Chaplin euh s' habiller pour sortir de son usine puisque les les les les c~ les capitales les grandes villes ne me disaient rien du tout bah euh oh bah de l' arrêt l' arrêt de Steve Mandanda à la suite de ce ballon arraché euh par les euh Argentins à la défense de cette équipe de France non mais même pas dans le fond je suis très très pudique et c' est vrai que bon je les vois pas partir le matin alors là vous faisiez des études de médecine déjà il y a un moment euh ils disaient que de toute manière dans ce boulevard vous remontez ils restent pas à Paris j~ j' ai j' ai fait mon PCB à Paris\n",
      "FENEC/spoken03-Rhapsodie.txt\n"
     ]
    }
   ],
   "source": [
    "for file in sorted(glob.glob(\"FENEC/*.txt\"))[11:]: \n",
    "    print(file)\n",
    "    all_entities = []\n",
    "    with open(file,\"r\") as f:\n",
    "        offset = 0\n",
    "        for line in f: \n",
    "            chunks = [line]\n",
    "            if len(line)>=1000:\n",
    "                # BRUTAL\n",
    "                # TO CHANGE\n",
    "                chunks = [line[1000*i:1000*(i+1)] for i in range(len(line)//1000)]\n",
    "            for chunk in chunks:    \n",
    "                entities = more_shots_qwen (chunk)\n",
    "                add_entities_index (entities, chunk, offset)\n",
    "                if 'entities' in entities:\n",
    "                    \n",
    "                    all_entities += (entities['entities'])\n",
    "                offset += len(chunk)\n",
    "    ann_file = \"systems-outputs/original-tagsets/qwen_more_shots/\"+os.path.basename(file).split(\".\")[0]+\".ann\"\n",
    "    with open(ann_file, \"w\") as f:\n",
    "        f.write (entities_to_ann (all_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fe921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
